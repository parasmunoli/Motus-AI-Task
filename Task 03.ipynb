{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing Libraries",
   "id": "bc8782cec30fab46"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T07:15:14.398053Z",
     "start_time": "2024-12-16T07:15:12.207102Z"
    }
   },
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 12:45:12.757344: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-16 12:45:12.760764: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-16 12:45:12.770598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734333312.787127   20575 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734333312.791883   20575 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-16 12:45:12.808961: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Initialize the Mediapipe pose detector",
   "id": "40f2508ed273c31c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T07:15:16.982486Z",
     "start_time": "2024-12-16T07:15:16.912609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ],
   "id": "564a37959145fd61",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734333316.975626   20575 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1734333316.979258   22068 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.2), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 17.0.6, DRM 3.57, 6.8.0-49-generic)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Start capturing video from the webcam",
   "id": "cc08704eb1e1e03c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T07:15:20.216991Z",
     "start_time": "2024-12-16T07:15:20.075033Z"
    }
   },
   "cell_type": "code",
   "source": "cap = cv2.VideoCapture(0)",
   "id": "60d25cac56200d03",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a88043734fb22932"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T07:15:52.066702Z",
     "start_time": "2024-12-16T07:15:49.677340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame from webcam.\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "        x_min = min([landmark.x for landmark in landmarks]) * frame.shape[1] - 40\n",
    "        x_max = max([landmark.x for landmark in landmarks]) * frame.shape[1] + 40\n",
    "        y_min = min([landmark.y for landmark in landmarks]) * frame.shape[0] - 50\n",
    "        y_max = max([landmark.y for landmark in landmarks]) * frame.shape[0] + 30\n",
    "\n",
    "        # Draw the bounding box around the detected human\n",
    "        cv2.rectangle(frame, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the video feed with pose landmarks and bounding box\n",
    "    cv2.imshow(\"Real-Time Human Movement Tracker\", frame)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "b4712e9db50ff31f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bfbccf25d2dfc5e6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
